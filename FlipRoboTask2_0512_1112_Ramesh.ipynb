{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f39fa1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_titles</th>\n",
       "      <th>job_Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Associate Healthcare Research and Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Clarivate</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Shell Pvt Ltd</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Shell Pvt Ltd</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Shell Pvt Ltd</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>MM STAFFING CAREER CONSULTANTS PRIVATE LIMITED</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Analyst | Neiman Marcus Group</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Talent500</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst II</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Management Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>1-12 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       job_titles         job_Location  \\\n",
       "0  Associate Healthcare Research and Data Analyst  Bangalore/Bengaluru   \n",
       "1                                    Data Analyst  Bangalore/Bengaluru   \n",
       "2                                    Data Analyst  Bangalore/Bengaluru   \n",
       "3                                    Data Analyst  Bangalore/Bengaluru   \n",
       "4                                    Data Analyst  Bangalore/Bengaluru   \n",
       "5                                    Data Analyst  Bangalore/Bengaluru   \n",
       "6                                Sr. Data Analyst  Bangalore/Bengaluru   \n",
       "7       Senior Data Analyst | Neiman Marcus Group  Bangalore/Bengaluru   \n",
       "8                          Senior Data Analyst II  Bangalore/Bengaluru   \n",
       "9                  Senior Data Management Analyst  Bangalore/Bengaluru   \n",
       "\n",
       "                                     Company_name Experience_required  \n",
       "0                                       Clarivate             0-2 Yrs  \n",
       "1                                   Shell Pvt Ltd             2-5 Yrs  \n",
       "2                                   Shell Pvt Ltd             3-5 Yrs  \n",
       "3                                   Shell Pvt Ltd             2-5 Yrs  \n",
       "4                                             ANZ             1-4 Yrs  \n",
       "5                                             ANZ             1-5 Yrs  \n",
       "6  MM STAFFING CAREER CONSULTANTS PRIVATE LIMITED             5-8 Yrs  \n",
       "7                                       Talent500            6-11 Yrs  \n",
       "8                                        Flipkart             2-4 Yrs  \n",
       "9                                     Wells Fargo            1-12 Yrs  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "# have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "# jobs data.\n",
    "# This task will be done in following steps:\n",
    "# 1. First get the webpage https://www.naukri.com/\n",
    "# 2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "# location” field.\n",
    "# 3. Then click the search button.\n",
    "# 4. Then scrape the data for the first 10 jobs results you get.\n",
    "# 5. Finally create a dataframe of the scraped data.\n",
    "# Note: All of the above steps have to be done in code. No step is to be done manually.\n",
    "    \n",
    "import selenium\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "Webdriver_Path = Service(\"C:\\\\DataTrained\\\\FlipRobo\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=Webdriver_Path)\n",
    "#driver = webdriver.Chrome(r\"C:\\DataTrained\\FlipRobo\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "# opening the URL\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "#maximize the window size  \n",
    "driver.maximize_window()  \n",
    "#delete the cookies  \n",
    "driver.delete_all_cookies()  \n",
    "driver.find_element(By.XPATH, \"//*[@id='root']/div[6]/div/div/div[1]/div/div/div/input\").send_keys(\"Data Analyst\")\n",
    "driver.find_element(By.XPATH, \"//*[@id='root']/div[6]/div/div/div[5]/div/div/div/input\").send_keys(\"Bangalore\")\n",
    "driver.find_element(By.XPATH, \"//div[@class='qsbSubmit']\").click()\n",
    "#time.sleep(3)\n",
    "driver.implicitly_wait(3) # seconds\n",
    "\n",
    "job_titles=[]\n",
    "job_Location = []\n",
    "Company = []\n",
    "Experience_required =[]\n",
    "\n",
    "title_tags = driver.find_elements(By.XPATH, \"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_titles.append(title)\n",
    "    #time.sleep(3)\n",
    "\n",
    "location_tags = driver.find_elements(By.XPATH, \"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags[0:10]:\n",
    "    loc = i.text\n",
    "    job_Location.append(loc)\n",
    "     \n",
    "company_tags = driver.find_elements(By.XPATH, \"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    comp = i.text\n",
    "    Company.append(comp)\n",
    "\n",
    "experience_tags = driver.find_elements(By.XPATH, \"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "for i in experience_tags[0:10]:\n",
    "    exp = i.text\n",
    "    Experience_required.append(exp)\n",
    " \n",
    "\n",
    "    #close the browser  \n",
    "driver.close()  \n",
    "\n",
    "scrape_list = {'job_titles':job_titles,'job_Location':job_Location,'Company_name':Company,'Experience_required':Experience_required}\n",
    "df = pd.DataFrame(scrape_list,columns =['job_titles','job_Location','Company_name','Experience_required'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fd61c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_titles</th>\n",
       "      <th>job_Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi, Hyderabad/Secu...</td>\n",
       "      <td>Tata Nexarc</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Nagpur, Pune</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist / AI-ML Engineer</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Hitachi Ltd.</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Manager-Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AMERICAN EXPRESS</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ACN - Applied Intelligence - Data Scientist - 09</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Noida, Kolkata, ...</td>\n",
       "      <td>Mindtree</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - II</td>\n",
       "      <td>Bangalore/Bengaluru, India, Mumbai (All Areas)</td>\n",
       "      <td>Bizongo</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>Baker Hughes</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Science - Engineering Manager</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi</td>\n",
       "      <td>Paytm</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         job_titles  \\\n",
       "0                  Analystics & Modeling Specialist   \n",
       "1                                    Data Scientist   \n",
       "2                                    Data Scientist   \n",
       "3                   Data Scientist / AI-ML Engineer   \n",
       "4                              Manager-Data Science   \n",
       "5  ACN - Applied Intelligence - Data Scientist - 09   \n",
       "6                                    Data Scientist   \n",
       "7                               Data Scientist - II   \n",
       "8                             Senior Data Scientist   \n",
       "9                Data Science - Engineering Manager   \n",
       "\n",
       "                                        job_Location      Company_name  \\\n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...         Accenture   \n",
       "1  Bangalore/Bengaluru, New Delhi, Hyderabad/Secu...       Tata Nexarc   \n",
       "2                  Bangalore/Bengaluru, Nagpur, Pune     Tech Mahindra   \n",
       "3                                Bangalore/Bengaluru      Hitachi Ltd.   \n",
       "4                                Bangalore/Bengaluru  AMERICAN EXPRESS   \n",
       "5                                Bangalore/Bengaluru         Accenture   \n",
       "6  Hybrid - Bangalore/Bengaluru, Noida, Kolkata, ...          Mindtree   \n",
       "7     Bangalore/Bengaluru, India, Mumbai (All Areas)           Bizongo   \n",
       "8                        Bangalore/Bengaluru, Mumbai      Baker Hughes   \n",
       "9                     Bangalore/Bengaluru, New Delhi             Paytm   \n",
       "\n",
       "  Experience_required  \n",
       "0             6-8 Yrs  \n",
       "1             4-8 Yrs  \n",
       "2             5-8 Yrs  \n",
       "3             3-7 Yrs  \n",
       "4             3-4 Yrs  \n",
       "5             2-6 Yrs  \n",
       "6            5-10 Yrs  \n",
       "7             3-6 Yrs  \n",
       "8             6-8 Yrs  \n",
       "9             3-5 Yrs  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2:Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    "# have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "# This task will be done in following steps:\n",
    "# 1. First get the webpage https://www.naukri.com/\n",
    "# 2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "# location” field.\n",
    "# 3. Then click the search button.\n",
    "# 4. Then scrape the data for the first 10 jobs results you get.\n",
    "# 5. Finally create a dataframe of the scraped data.\n",
    "# Note: All of the above steps have to be done in code. No step is to be done manually.\n",
    "import selenium\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "#from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "Webdriver_Path = Service(\"C:\\\\DataTrained\\\\FlipRobo\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=Webdriver_Path)\n",
    "#driver = webdriver.Chrome(r\"C:\\DataTrained\\FlipRobo\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "# opening the URL\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "#maximize the window size  \n",
    "driver.maximize_window()  \n",
    "#delete the cookies  \n",
    "driver.delete_all_cookies()  \n",
    "driver.find_element(By.XPATH, \"//*[@id='root']/div[6]/div/div/div[1]/div/div/div/input\").send_keys(\"Data Scientist\")\n",
    "driver.find_element(By.XPATH, \"//*[@id='root']/div[6]/div/div/div[5]/div/div/div/input\").send_keys(\"Bangalore\")\n",
    "driver.find_element(By.XPATH, \"//div[@class='qsbSubmit']\").click()\n",
    "#time.sleep(3)\n",
    "driver.implicitly_wait(3) # seconds\n",
    "\n",
    "job_titles=[]\n",
    "job_Location = []\n",
    "Company = []\n",
    "Experience_required =[]\n",
    "\n",
    "title_tags = driver.find_elements(By.XPATH, \"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_titles.append(title)\n",
    "    #time.sleep(3)\n",
    "        \n",
    "#print(job_titles)\n",
    "\n",
    "location_tags = driver.find_elements(By.XPATH, \"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags[0:10]:\n",
    "    loc = i.text\n",
    "    job_Location.append(loc)\n",
    "     \n",
    "company_tags = driver.find_elements(By.XPATH, \"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    comp = i.text\n",
    "    Company.append(comp)\n",
    "    \n",
    "experience_tags = driver.find_elements(By.XPATH, \"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "for i in experience_tags[0:10]:\n",
    "    exp = i.text\n",
    "    Experience_required.append(exp)\n",
    " \n",
    "\n",
    "#close the browser  \n",
    "driver.close()  \n",
    "\n",
    "scrape_list = {'job_titles':job_titles,'job_Location':job_Location,'Company_name':Company,'Experience_required':Experience_required}\n",
    "df = pd.DataFrame(scrape_list,columns =['job_titles','job_Location','Company_name','Experience_required'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "931a1f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_titles</th>\n",
       "      <th>job_Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Artificial Intelligence/Computer Vision Engine...</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Vicara</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Activation Specialist - Adobe Target</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Okda Solutions</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Temp. WFH - Noida</td>\n",
       "      <td>NGI Ventures</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Dehradun, Hyderabad/Secunderabad, Gurgaon/Guru...</td>\n",
       "      <td>torcai digital media</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Americana Restaurants (india)</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>URGENT: Data Scientist | Gurugram | 5 Days Wor...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Digilytics</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Alliance Recruitment Agency</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jr. Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Dataflow</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Razor Group Gmbh</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          job_titles  \\\n",
       "0  Artificial Intelligence/Computer Vision Engine...   \n",
       "1          Data Activation Specialist - Adobe Target   \n",
       "2                                     Data Scientist   \n",
       "3                  Data Scientist - Engine Algorithm   \n",
       "4                                     Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6  URGENT: Data Scientist | Gurugram | 5 Days Wor...   \n",
       "7                                     Data Scientist   \n",
       "8                                 Jr. Data Scientist   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                        job_Location  \\\n",
       "0  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "1  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "2                                  Temp. WFH - Noida   \n",
       "3  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "4  Dehradun, Hyderabad/Secunderabad, Gurgaon/Guru...   \n",
       "5                                   Gurgaon/Gurugram   \n",
       "6                                   Gurgaon/Gurugram   \n",
       "7                                              Noida   \n",
       "8                                              Noida   \n",
       "9                                          New Delhi   \n",
       "\n",
       "                    Company_name Experience_required  \n",
       "0                         Vicara             1-3 Yrs  \n",
       "1                 Okda Solutions            7-10 Yrs  \n",
       "2                   NGI Ventures             1-5 Yrs  \n",
       "3                   Primo Hiring             1-3 Yrs  \n",
       "4           torcai digital media             2-7 Yrs  \n",
       "5  Americana Restaurants (india)             3-8 Yrs  \n",
       "6                     Digilytics             2-5 Yrs  \n",
       "7    Alliance Recruitment Agency             3-4 Yrs  \n",
       "8                       Dataflow             1-3 Yrs  \n",
       "9               Razor Group Gmbh             2-3 Yrs  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "# You have to use the location and salary filter.\n",
    "# You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "# You have to scrape the job-title, job-location, company name, experience required.\n",
    "# The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "# The task will be done as shown in the below steps:\n",
    "# 1. first get the webpage https://www.naukri.com/\n",
    "# 2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "# 3. Then click the search button.\n",
    "# 4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "# 5. Then scrape the data for the first 10 jobs results you get.\n",
    "# 6. Finally create a dataframe of the scraped data.\n",
    "# Note: All of the above steps have to be done in code. No step is to be done manually.\n",
    "import selenium\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "#from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "Webdriver_Path = Service(\"C:\\\\DataTrained\\\\FlipRobo\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=Webdriver_Path)\n",
    "#driver = webdriver.Chrome(r\"C:\\DataTrained\\FlipRobo\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "# opening the URL\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "#maximize the window size  \n",
    "driver.maximize_window()  \n",
    "#delete the cookies  \n",
    "driver.delete_all_cookies()  \n",
    "driver.find_element(By.XPATH, \"//*[@id='root']/div[6]/div/div/div[1]/div/div/div/input\").send_keys(\"Data Scientist\")\n",
    "#driver.find_element(By.XPATH, \"//*[@id='root']/div[6]/div/div/div[5]/div/div/div/input\").send_keys(\"Bangalore\")\n",
    "driver.find_element(By.XPATH, \"//div[@class='qsbSubmit']\").click()\n",
    "#time.sleep(3)\n",
    "driver.implicitly_wait(3) # seconds\n",
    "\n",
    "#location filter to be used is “Delhi/NCR”\n",
    "driver.find_element(By.XPATH, \"//*[@id='root']/div[4]/div/div/section[1]/div[2]/div[5]/div[2]/div[2]/label/i\").click()\n",
    "#salary filter to be used is “3-6” lakhs\n",
    "driver.find_element(By.XPATH, \"//*[@id='root']/div[4]/div/div/section[1]/div[2]/div[6]/div[2]/div[2]/label/i\").click()\n",
    "\n",
    "job_titles=[]\n",
    "job_Location = []\n",
    "Company = []\n",
    "Experience_required =[]\n",
    "\n",
    "title_tags = driver.find_elements(By.XPATH, \"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_titles.append(title)\n",
    "    #time.sleep(3)\n",
    "        \n",
    "#print(job_titles)\n",
    "\n",
    "location_tags = driver.find_elements(By.XPATH, \"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags[0:10]:\n",
    "    loc = i.text\n",
    "    job_Location.append(loc)\n",
    "     \n",
    "company_tags = driver.find_elements(By.XPATH, \"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    comp = i.text\n",
    "    Company.append(comp)\n",
    "    \n",
    "experience_tags = driver.find_elements(By.XPATH, \"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "for i in experience_tags[0:10]:\n",
    "    exp = i.text\n",
    "    Experience_required.append(exp)\n",
    " \n",
    "\n",
    "#close the browser  \n",
    "driver.close()  \n",
    "\n",
    "scrape_list = {'job_titles':job_titles,'job_Location':job_Location,'Company_name':Company,'Experience_required':Experience_required}\n",
    "df = pd.DataFrame(scrape_list,columns =['job_titles','job_Location','Company_name','Experience_required'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dc468f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>ProductDescription</th>\n",
       "      <th>Product_Price</th>\n",
       "      <th>Product_Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>Riding Glasses, Night Vision Spectacle Sunglas...</td>\n",
       "      <td>₹129</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹489</td>\n",
       "      <td>38% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (53)</td>\n",
       "      <td>₹129</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Cat-eye, Retro Square, Oval, Rou...</td>\n",
       "      <td>₹149</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹599</td>\n",
       "      <td>40% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>Riding Glasses, Night Vision Retro Square, Spe...</td>\n",
       "      <td>₹129</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>DEIXELS</td>\n",
       "      <td>Polarized, UV Protection, Riding Glasses Wayfa...</td>\n",
       "      <td>₹218</td>\n",
       "      <td>63% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, UV Protection Retro Square Sunglass...</td>\n",
       "      <td>₹616</td>\n",
       "      <td>69% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Cat-eye S...</td>\n",
       "      <td>₹949</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>UV Protection Oval Sunglasses (Free Size)</td>\n",
       "      <td>₹196</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Brand                                 ProductDescription  \\\n",
       "0      LIZA ANGEL  Riding Glasses, Night Vision Spectacle Sunglas...   \n",
       "1        Fastrack   UV Protection Rectangular Sunglasses (Free Size)   \n",
       "2      PHENOMENAL         UV Protection Retro Square Sunglasses (53)   \n",
       "3       Elligator  UV Protection Cat-eye, Retro Square, Oval, Rou...   \n",
       "4        Fastrack      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "..            ...                                                ...   \n",
       "95     LIZA ANGEL  Riding Glasses, Night Vision Retro Square, Spe...   \n",
       "96        DEIXELS  Polarized, UV Protection, Riding Glasses Wayfa...   \n",
       "97      ROYAL SON  Polarized, UV Protection Retro Square Sunglass...   \n",
       "98  VINCENT CHASE  by Lenskart Polarized, UV Protection Cat-eye S...   \n",
       "99      New Specs          UV Protection Oval Sunglasses (Free Size)   \n",
       "\n",
       "   Product_Price Product_Discount  \n",
       "0           ₹129          87% off  \n",
       "1           ₹489          38% off  \n",
       "2           ₹129          87% off  \n",
       "3           ₹149          75% off  \n",
       "4           ₹599          40% off  \n",
       "..           ...              ...  \n",
       "95          ₹129          87% off  \n",
       "96          ₹218          63% off  \n",
       "97          ₹616          69% off  \n",
       "98          ₹949          52% off  \n",
       "99          ₹196          80% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "# 1. Brand\n",
    "# 2. ProductDescription\n",
    "# 3. Price\n",
    "# The attributes which you have to scrape is ticked marked in the below image\n",
    "# To scrape the data you have to go through following steps:\n",
    "# 1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "# 2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and\n",
    "# click the search icon\n",
    "# 3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the\n",
    "# required data as usual.\n",
    "# 4.After scraping data from the first page, go to the “Next” Button at the bottom other page , then\n",
    "# click on it.\n",
    "# 5. Now scrape data from this page as usual\n",
    "# 6. Repeat this until you get data for 100 sunglasses.\n",
    "# Note: That all of the above steps have to be done by coding only and not manually.\n",
    "import selenium\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "#from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "Webdriver_Path = Service(\"C:\\\\DataTrained\\\\FlipRobo\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=Webdriver_Path)\n",
    "#driver = webdriver.Chrome(r\"C:\\DataTrained\\FlipRobo\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "# opening the URL\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "#maximize the window size  \n",
    "driver.maximize_window()  \n",
    "#delete the cookies  \n",
    "driver.delete_all_cookies()\n",
    "\n",
    "driver.find_element(By.XPATH, \"//button[@class='_2KpZ6l _2doB4z']\").click()\n",
    "driver.find_element(By.XPATH, \"//input[@class='_3704LK']\").send_keys(\"sunglasses\")\n",
    "driver.find_element(By.XPATH, \"//button[@class='L0Z3Pu']\").click()\n",
    "#time.sleep(3)\n",
    "driver.implicitly_wait(2) # seconds\n",
    "\n",
    "Brand=[]\n",
    "ProductDescription = []\n",
    "Price = []\n",
    "Discount =[]\n",
    "\n",
    "start =0\n",
    "end =3\n",
    "for page in range(start,end):\n",
    "    Brand_tags = driver.find_elements(By.XPATH, \"//div[@class='_2WkVRV']\")\n",
    "    for i in Brand_tags:\n",
    "        Brand.append(i.text.strip())\n",
    "       \n",
    "    ProductDesc_tags = driver.find_elements(By.XPATH, \"//a[@class='IRpwTa']\")\n",
    "    for i in ProductDesc_tags:\n",
    "        ProductDescription.append(i.text.strip())\n",
    "            \n",
    "    Price_tags = driver.find_elements(By.XPATH, \"//div[@class='_30jeq3']\")\n",
    "    for i in Price_tags:\n",
    "        Price.append(i.text.strip())\n",
    "            \n",
    "    Discount_tags = driver.find_elements(By.XPATH, \"//div[@class='_3Ay6Sb']//span\")\n",
    "    for i in Discount_tags:\n",
    "        Discount.append(i.text.strip())\n",
    "           \n",
    "    if page == 0:     \n",
    "        next_button = driver.find_element(By.XPATH, \"//a[@class='_1LKTO3']\")\n",
    "        next_button.click()\n",
    "        time.sleep(2)\n",
    "    else:\n",
    "        next_button = driver.find_element(By.XPATH, \"//a[12][@class='_1LKTO3']//span[1]\")\n",
    "        next_button.click()\n",
    "        time.sleep(2)\n",
    "\n",
    "#close the browser  \n",
    "driver.close() \n",
    "#DataFrame of Brand,ProductDesc,Price and Discount as mentioned on the image\n",
    "flipkart_sunglasslist = {'Brand':Brand,'ProductDescription':ProductDescription,'Product_Price':Price,'Product_Discount':Discount}\n",
    "df = pd.DataFrame(flipkart_sunglasslist,columns =['Brand','ProductDescription','Product_Price','Product_Discount'])\n",
    "df.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8be42c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>ReviewSummary</th>\n",
       "      <th>FullReview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Value-for-money</td>\n",
       "      <td>I'm Really happy with the product\\nDelivery wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3</td>\n",
       "      <td>Does the job</td>\n",
       "      <td>phone is good but in display is 720p lcd in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>This is my first ever iPhone.\\nAnd I truly don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>A wort full value for money decision it’s . Si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>Dear friends... I want to share my experience ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>Can’t beat the software and hardware integrati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating        ReviewSummary  \\\n",
       "0       5       Simply awesome   \n",
       "1       5     Perfect product!   \n",
       "2       5  Best in the market!   \n",
       "3       4      Value-for-money   \n",
       "4       5    Worth every penny   \n",
       "..    ...                  ...   \n",
       "95      3         Does the job   \n",
       "96      5               Super!   \n",
       "97      5            Brilliant   \n",
       "98      5            Must buy!   \n",
       "99      5              Awesome   \n",
       "\n",
       "                                           FullReview  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   I'm Really happy with the product\\nDelivery wa...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  phone is good but in display is 720p lcd in th...  \n",
       "96  This is my first ever iPhone.\\nAnd I truly don...  \n",
       "97  A wort full value for money decision it’s . Si...  \n",
       "98  Dear friends... I want to share my experience ...  \n",
       "99  Can’t beat the software and hardware integrati...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "# https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market\n",
    "# place=FLIPKART\n",
    "# As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "# 1. Rating\n",
    "# 2. Review summary\n",
    "# 3. Full review\n",
    "# 4. You have to scrape this data for first 100 reviews.\n",
    "\n",
    "import selenium\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "#from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "Webdriver_Path = Service(\"C:\\\\DataTrained\\\\FlipRobo\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=Webdriver_Path)\n",
    "#driver = webdriver.Chrome(r\"C:\\DataTrained\\FlipRobo\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "# opening the URL\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market\")\n",
    "#maximize the window size  \n",
    "driver.maximize_window()  \n",
    "#delete the cookies  \n",
    "driver.delete_all_cookies()\n",
    "driver.implicitly_wait(2) # seconds\n",
    "\n",
    "Rating=[]\n",
    "ReviewSummary = []\n",
    "FullReview = []\n",
    "\n",
    "start = 0\n",
    "last = 10\n",
    "for page in range(start,last):\n",
    "    time.sleep(2)\n",
    "    Rating_tags = driver.find_elements(By.XPATH, \"//div[@class='_3LWZlK _1BLPMq' or @class='_3LWZlK _1rdVr6 _1BLPMq']\")\n",
    "    for i in Rating_tags:\n",
    "        Rating.append(i.text.strip()) \n",
    "              \n",
    "    reviewSummary_tags = driver.find_elements(By.XPATH, \"//p[@class='_2-N8zT']\")\n",
    "    for i in reviewSummary_tags:\n",
    "        ReviewSummary.append(i.text.strip()) \n",
    "       \n",
    "    FullReview_tags = driver.find_elements(By.XPATH, \"//div[@class='t-ZTKy']\")\n",
    "    for i in FullReview_tags:\n",
    "        FullReview.append(i.text.strip()) \n",
    "        time.sleep(2)\n",
    "        \n",
    "    if page == 0:    \n",
    "        #next_button = driver.find_element(By.XPATH, \"//a[@class='_1LKTO3']\")\n",
    "        driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "        next_button = driver.find_element(By.CLASS_NAME, \"_1LKTO3\")\n",
    "        time.sleep(2)\n",
    "        next_button.click()  \n",
    "        time.sleep(2)\n",
    "    else:\n",
    "        next_button = driver.find_element(By.XPATH, \"//a[12][@class='_1LKTO3']//span[1]\")\n",
    "        time.sleep(2)\n",
    "        next_button.click()\n",
    "\n",
    "#close the browser  \n",
    "driver.close()\n",
    "\n",
    "\n",
    "#DataFrame of Rating,ProductDesc,ReviewSummary and FullReview for apple-iphone-11-black-64-gb/product-reviews\n",
    "flipkart_iphone11 = {'Rating':Rating,'ReviewSummary':ReviewSummary,'FullReview':FullReview}\n",
    "df = pd.DataFrame(flipkart_iphone11,columns =['Rating','ReviewSummary','FullReview'])\n",
    "# df = pd.DataFrame.from_dict(flipkart_iphone11, orient='index')\n",
    "# df = df.transpose()\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13c6691a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>ProductDescription</th>\n",
       "      <th>Product_Price</th>\n",
       "      <th>Product_Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shozie</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹295</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SFR</td>\n",
       "      <td>PLANCK Smart Grey Lace-Ups Casuals Sneakers Sn...</td>\n",
       "      <td>₹199</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Mesh | Ultralightweight | Comfortable | Breath...</td>\n",
       "      <td>₹359</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TR</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹299</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>bacca bucci</td>\n",
       "      <td>Comfy Mid-Top Casual Chunky Streetwear Fashion...</td>\n",
       "      <td>₹1,683</td>\n",
       "      <td>54% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>RS-X PUZZLE Sneakers For Men</td>\n",
       "      <td>₹4,139</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹381</td>\n",
       "      <td>40% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹599</td>\n",
       "      <td>49% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Brave Sneakers For Men</td>\n",
       "      <td>₹1,650</td>\n",
       "      <td>37% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Brand                                 ProductDescription  \\\n",
       "0        Labbin                                   Sneakers For Men   \n",
       "1        Shozie                                   Sneakers For Men   \n",
       "2           SFR  PLANCK Smart Grey Lace-Ups Casuals Sneakers Sn...   \n",
       "3          aadi  Mesh | Ultralightweight | Comfortable | Breath...   \n",
       "4            TR                                   Sneakers For Men   \n",
       "..          ...                                                ...   \n",
       "95  bacca bucci  Comfy Mid-Top Casual Chunky Streetwear Fashion...   \n",
       "96         PUMA                       RS-X PUZZLE Sneakers For Men   \n",
       "97    Deals4you                                 Sneakers For Women   \n",
       "98     RapidBox                                   Sneakers For Men   \n",
       "99         PUMA                             Brave Sneakers For Men   \n",
       "\n",
       "   Product_Price Product_Discount  \n",
       "0           ₹399          60% off  \n",
       "1           ₹295          70% off  \n",
       "2           ₹199          66% off  \n",
       "3           ₹359          82% off  \n",
       "4           ₹299          80% off  \n",
       "..           ...              ...  \n",
       "95        ₹1,683          54% off  \n",
       "96        ₹4,139          80% off  \n",
       "97          ₹381          40% off  \n",
       "98          ₹599          49% off  \n",
       "99        ₹1,650          37% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the\n",
    "# search field.\n",
    "# You have to scrape 4 attributes of each sneaker:\n",
    "# 1. Brand\n",
    "# 2. ProductDescription\n",
    "# 3. Price\n",
    "# As shown in the below image, you have to scrape the tick marked attributes.\n",
    "\n",
    "import selenium\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "#from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "Webdriver_Path = Service(\"C:\\\\DataTrained\\\\FlipRobo\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=Webdriver_Path)\n",
    "#driver = webdriver.Chrome(r\"C:\\DataTrained\\FlipRobo\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "# opening the URL\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "#maximize the window size  \n",
    "driver.maximize_window()  \n",
    "#delete the cookies  \n",
    "driver.delete_all_cookies()\n",
    "\n",
    "driver.find_element(By.XPATH, \"//button[@class='_2KpZ6l _2doB4z']\").click()\n",
    "driver.find_element(By.XPATH, \"//input[@class='_3704LK']\").send_keys(\"sneakers\")\n",
    "driver.find_element(By.XPATH, \"//button[@class='L0Z3Pu']\").click()\n",
    "#time.sleep(3)\n",
    "driver.implicitly_wait(2) # seconds\n",
    "\n",
    "Brand=[]\n",
    "ProductDescription = []\n",
    "Price = []\n",
    "Discount =[]\n",
    "\n",
    "start =0\n",
    "end =3\n",
    "for page in range(start,end):\n",
    "    Brand_tags = driver.find_elements(By.XPATH, \"//div[@class='_2WkVRV']\")\n",
    "    for i in Brand_tags:\n",
    "        Brand.append(i.text.strip())\n",
    "       \n",
    "    ProductDesc_tags = driver.find_elements(By.XPATH, \"//a[@class='IRpwTa' or @class='IRpwTa _2-ICcC']\")\n",
    "    for i in ProductDesc_tags:\n",
    "        ProductDescription.append(i.text.strip())\n",
    "            \n",
    "    Price_tags = driver.find_elements(By.XPATH, \"//div[@class='_30jeq3']\")\n",
    "    for i in Price_tags:\n",
    "        Price.append(i.text.strip())\n",
    "            \n",
    "    Discount_tags = driver.find_elements(By.XPATH, \"//div[@class='_3Ay6Sb']//span\")\n",
    "    for i in Discount_tags:\n",
    "        Discount.append(i.text.strip())\n",
    "           \n",
    "    if page == 0:     \n",
    "        next_button = driver.find_element(By.XPATH, \"//a[@class='_1LKTO3']\")\n",
    "        next_button.click()\n",
    "        time.sleep(2)\n",
    "    else:\n",
    "        next_button = driver.find_element(By.XPATH, \"//a[12][@class='_1LKTO3']//span[1]\")\n",
    "        next_button.click()\n",
    "        time.sleep(2)\n",
    "\n",
    "#close the browser  \n",
    "driver.close() \n",
    "#DataFrame of Brand,ProductDesc,Price and Discount as mentioned on the image\n",
    "flipkart_sneakerslist = {'Brand':Brand,'ProductDescription':ProductDescription,'Product_Price':Price,'Product_Discount':Discount}\n",
    "#df = pd.DataFrame(flipkart_sneakerslist,columns =['Brand','ProductDescription','Product_Price','Product_Discount'])\n",
    "df = pd.DataFrame.from_dict(flipkart_sneakerslist, orient='index')\n",
    "df = df.transpose()\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60c3263d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14 inc...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>82,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Samsung Galaxy Book2 360 Intel 12th Gen i7 Evo...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>94,391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>95,546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acer Nitro 5 Gaming Laptop Intel core i7 11th ...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Renewed) HP ProBook 430 G3 6th Gen Intel Core...</td>\n",
       "      <td>3.3</td>\n",
       "      <td>24,949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14 inc...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>82,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>89,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Victus Gaming Latest 12th Gen Intel Core i7...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>82,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 12th Gen Intel Core i7 1...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>82,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS TUF Gaming F17 (2022), 17.3\"(43.94 cms) F...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1,06,874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Ratings     price\n",
       "0  HP Pavilion x360 11th Gen Intel Core i7 14 inc...     4.4    82,490\n",
       "1  Samsung Galaxy Book2 360 Intel 12th Gen i7 Evo...     4.2    94,391\n",
       "2  HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...     4.0    95,546\n",
       "3  Acer Nitro 5 Gaming Laptop Intel core i7 11th ...     3.9    79,990\n",
       "4  (Renewed) HP ProBook 430 G3 6th Gen Intel Core...     3.3    24,949\n",
       "5  HP Pavilion x360 11th Gen Intel Core i7 14 inc...     4.4    82,490\n",
       "6  HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...     4.2    89,000\n",
       "7  HP Victus Gaming Latest 12th Gen Intel Core i7...     4.3    82,490\n",
       "8  Lenovo IdeaPad Slim 5 12th Gen Intel Core i7 1...     4.2    82,990\n",
       "9  ASUS TUF Gaming F17 (2022), 17.3\"(43.94 cms) F...     4.0  1,06,874"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q7: Go to webpage https://www.amazon.in/\n",
    "# Enter “Laptop” in the search field and then click the search icon.\n",
    "# Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "# After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "# 1. Title\n",
    "# 2. Ratings\n",
    "# 3. Price\n",
    "\n",
    "\n",
    "import selenium\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "#from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "Webdriver_Path = Service(\"C:\\\\DataTrained\\\\FlipRobo\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=Webdriver_Path)\n",
    "#driver = webdriver.Chrome(r\"C:\\DataTrained\\FlipRobo\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "# opening the URL\n",
    "driver.get(\"https://www.amazon.in/\")\n",
    "#maximize the window size  \n",
    "driver.maximize_window()  \n",
    "#delete the cookies  \n",
    "driver.delete_all_cookies()\n",
    "\n",
    "driver.find_element(By.ID, \"twotabsearchtextbox\").send_keys(\"Laptop\")\n",
    "driver.find_element(By.ID, \"nav-search-submit-button\").click()\n",
    "time.sleep(1)\n",
    "#set CPU Type filter to “Intel Core i7”\n",
    "#driver.find_element(By.ID, \"p_n_feature_thirteen_browse-bin/12598163031\").click()\n",
    "#driver.find_element(By.XPATH, \"//li[contains(@aria-label, 'Intel Core i7')]\").click()\n",
    "driver.find_element(By.XPATH, \"//li[contains(@aria-label, 'Intel Core i7')]//i[@class='a-icon a-icon-checkbox']\").click()\n",
    "#driver.implicitly_wait(2) # seconds\n",
    "time.sleep(3)\n",
    "\n",
    "Title=[]\n",
    "Ratings = []\n",
    "price = []\n",
    "\n",
    "title_tags = driver.find_elements(By.XPATH, \"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']\")\n",
    "for i in title_tags[0:10]:\n",
    "    Title.append(i.text.strip())\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "Ratings_tags = driver.find_elements(By.XPATH, \"//div[@class='a-section a-spacing-none a-spacing-top-micro']//span[@class='a-size-base']\")\n",
    "for i in Ratings_tags[0:10]:\n",
    "    Ratings.append(i.text.strip())\n",
    "    time.sleep(1)\n",
    "\n",
    "     \n",
    "price_tags = driver.find_elements(By.XPATH, \"//a[@class='a-size-base a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal']//span[@class='a-price-whole']\")\n",
    "for i in price_tags[0:10]:\n",
    "    price.append(i.text.strip())\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "#close the browser  \n",
    "driver.close()  \n",
    "\n",
    "# print(Title)\n",
    "# print(Ratings)\n",
    "# print(price)\n",
    "\n",
    "Amazon_list = {'Title':Title,'Ratings':Ratings,'price':price}\n",
    "# df = pd.DataFrame(Amazon_list,columns =['Title','Ratings','price'])\n",
    "# df.head(10)\n",
    "#Second way of displaying on DataFrame\n",
    "df2 = pd.DataFrame.from_dict(Amazon_list, orient='index')\n",
    "df2 = df2.transpose()\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91bc7d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Author</th>\n",
       "      <th>TypeOfQuotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Regret for the things we did can be tempered b...</td>\n",
       "      <td>Sydney J. Harris</td>\n",
       "      <td>Love, Inspirational, Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>America... just a nation of two hundred millio...</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Gun, Two, Qualms About</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>For every disciplined effort there is a multip...</td>\n",
       "      <td>Jim Rohn</td>\n",
       "      <td>Inspirational, Greatness, Best Effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The spiritual journey is individual, highly pe...</td>\n",
       "      <td>Ram Dass</td>\n",
       "      <td>Spiritual, Truth, Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>The mind is not a vessel to be filled but a fi...</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Inspirational, Leadership, Education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Quote              Author  \\\n",
       "0    The essence of strategy is choosing what not t...      Michael Porter   \n",
       "1    One cannot and must not try to erase the past ...          Golda Meir   \n",
       "2    Patriotism means to stand by the country. It d...  Theodore Roosevelt   \n",
       "3    Death is something inevitable. When a man has ...      Nelson Mandela   \n",
       "4    You have to love a nation that celebrates its ...        Erma Bombeck   \n",
       "..                                                 ...                 ...   \n",
       "995  Regret for the things we did can be tempered b...    Sydney J. Harris   \n",
       "996  America... just a nation of two hundred millio...  Hunter S. Thompson   \n",
       "997  For every disciplined effort there is a multip...            Jim Rohn   \n",
       "998  The spiritual journey is individual, highly pe...            Ram Dass   \n",
       "999  The mind is not a vessel to be filled but a fi...            Plutarch   \n",
       "\n",
       "                                 TypeOfQuotes  \n",
       "0    Essence, Deep Thought, Transcendentalism  \n",
       "1                   Inspiration, Past, Trying  \n",
       "2                         Country, Peace, War  \n",
       "3          Inspirational, Motivational, Death  \n",
       "4                4th Of July, Food, Patriotic  \n",
       "..                                        ...  \n",
       "995         Love, Inspirational, Motivational  \n",
       "996                    Gun, Two, Qualms About  \n",
       "997     Inspirational, Greatness, Best Effort  \n",
       "998                    Spiritual, Truth, Yoga  \n",
       "999      Inspirational, Leadership, Education  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "# The above task will be done in following steps:\n",
    "# 1.First get the webpage https://www.azquotes.com/\n",
    "# 2. Click on Top Quotes\n",
    "# 3. Than scrap a) Quote b) Author c) Type Of Quotes\n",
    "import selenium\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "#from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "Webdriver_Path = Service(\"C:\\\\DataTrained\\\\FlipRobo\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=Webdriver_Path)\n",
    "#driver = webdriver.Chrome(r\"C:\\DataTrained\\FlipRobo\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "# opening the URL\n",
    "driver.get(\"https://www.azquotes.com/\")\n",
    "#maximize the window size  \n",
    "driver.maximize_window()  \n",
    "#delete the cookies  \n",
    "driver.delete_all_cookies()\n",
    "driver.implicitly_wait(2) # seconds\n",
    "#Click on Top Quotes\n",
    "driver.find_element(By.XPATH, \"//*[@id='menu']/div/div[3]/ul/li[5]/a\").click()\n",
    "time.sleep(2)\n",
    "\n",
    "Quote=[]\n",
    "Author = []\n",
    "TypeOfQuotes = []\n",
    "\n",
    "start = 0\n",
    "last = 10\n",
    "for page in range(start,last):\n",
    "    time.sleep(3)\n",
    "    Quote_tags = driver.find_elements(By.XPATH, \"//a[@class='title']\")\n",
    "    for i in Quote_tags:\n",
    "        Quote.append(i.text.strip()) \n",
    "              \n",
    "    Author_tags = driver.find_elements(By.XPATH, \"//div[@class='author']//a\")\n",
    "    for i in Author_tags:\n",
    "        Author.append(i.text.strip()) \n",
    "       \n",
    "    TypeOfQuotes_tags = driver.find_elements(By.XPATH, \"//div[@class='tags']\")\n",
    "    for i in TypeOfQuotes_tags:\n",
    "        TypeOfQuotes.append(i.text.strip()) \n",
    "    \n",
    "    time.sleep(2)\n",
    "    #next_button = driver.find_element(By.XPATH, \"//li[@class='next']\")\n",
    "    if page <= 8:\n",
    "        next_button = driver.find_element(By.XPATH, \"(//li[@class='next']//a)[1]\")\n",
    "        time.sleep(2)\n",
    "        next_button.click()  \n",
    "        time.sleep(1)  \n",
    "    \n",
    "\n",
    "#close the browser  \n",
    "driver.close()\n",
    "\n",
    "#DataFrame of Rating,ProductDesc,ReviewSummary and FullReview for apple-iphone-11-black-64-gb/product-reviews\n",
    "azquotes_list = {'Quote':Quote,'Author':Author,'TypeOfQuotes':TypeOfQuotes}\n",
    "df = pd.DataFrame(azquotes_list,columns =['Quote','Author','TypeOfQuotes'])\n",
    "# df = pd.DataFrame.from_dict(flipkart_iphone11, orient='index')\n",
    "# df = df.transpose()\n",
    "df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adf5d975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMName</th>\n",
       "      <th>Born-Dead</th>\n",
       "      <th>Term of office</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jawahar Lal Nehru</td>\n",
       "      <td>(1889–1964)</td>\n",
       "      <td>15 August 1947 to 27 May 1964\\n16 years, 286 days</td>\n",
       "      <td>The first prime minister of India and the long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gulzarilal Nanda (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>27 May 1964 to 9 June 1964,\\n13 days</td>\n",
       "      <td>First acting PM of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lal Bahadur Shastri</td>\n",
       "      <td>(1904–1966)</td>\n",
       "      <td>9 June 1964 to 11 January 1966\\n1 year, 216 days</td>\n",
       "      <td>He has given the slogan of 'Jai Jawan Jai Kisa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gulzari Lal Nanda  (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>11 January 1966 to 24 January 1966\\n13 days</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917–1984)</td>\n",
       "      <td>24 January 1966 to 24 March 1977\\n11 years, 59...</td>\n",
       "      <td>First female Prime Minister of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Morarji Desai</td>\n",
       "      <td>(1896–1995)</td>\n",
       "      <td>24 March 1977 to  28 July 1979 \\n2 year, 126 days</td>\n",
       "      <td>Oldest to become PM (81 years old) and first t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Charan Singh</td>\n",
       "      <td>(1902–1987)</td>\n",
       "      <td>28 July 1979 to 14 January 1980\\n170 days</td>\n",
       "      <td>Only PM who did not face the Parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917–1984)</td>\n",
       "      <td>14 January 1980 to 31 October 1984\\n4 years, 2...</td>\n",
       "      <td>The first lady who served as PM for the second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rajiv Gandhi</td>\n",
       "      <td>(1944–1991)</td>\n",
       "      <td>31 October 1984 to 2 December 1989\\n5 years, 3...</td>\n",
       "      <td>Youngest to become PM (40 years old)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>V. P. Singh</td>\n",
       "      <td>(1931–2008)</td>\n",
       "      <td>2 December 1989 to 10 November 1990\\n343 days</td>\n",
       "      <td>First PM to step down after a vote of no confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chandra Shekhar</td>\n",
       "      <td>(1927–2007)</td>\n",
       "      <td>10 November 1990 to 21 June 1991\\n223 days</td>\n",
       "      <td>He belongs to  Samajwadi Janata Party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P. V. Narasimha Rao</td>\n",
       "      <td>(1921–2004)</td>\n",
       "      <td>21 June 1991 to 16 May 1996\\n4 years, 330 days</td>\n",
       "      <td>First PM from south India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924- 2018)</td>\n",
       "      <td>16 May 1996 to 1 June 1996\\n16 days</td>\n",
       "      <td>PM for shortest tenure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>H. D. Deve Gowda</td>\n",
       "      <td>(born 1933)</td>\n",
       "      <td>1 June 1996 to 21 April 1997\\n324 days</td>\n",
       "      <td>He belongs to  Janata Dal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Inder Kumar Gujral</td>\n",
       "      <td>(1919–2012)</td>\n",
       "      <td>21 April 1997 to 19 March 1998 \\n332 days</td>\n",
       "      <td>------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924-2018)</td>\n",
       "      <td>19 March 1998 to 22 May 2004 \\n6 years, 64 days</td>\n",
       "      <td>The first non-congress PM who completed a full...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Manmohan Singh</td>\n",
       "      <td>(born 1932)</td>\n",
       "      <td>22 May 2004 to 26 May 2014   \\n10 years, 4 days</td>\n",
       "      <td>First Sikh PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>(born 1950)</td>\n",
       "      <td>26 May 2014 - Present</td>\n",
       "      <td>4th Prime Minister of India who served two con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         PMName     Born-Dead  \\\n",
       "0             Jawahar Lal Nehru   (1889–1964)   \n",
       "1     Gulzarilal Nanda (Acting)   (1898-1998)   \n",
       "2           Lal Bahadur Shastri   (1904–1966)   \n",
       "3   Gulzari Lal Nanda  (Acting)   (1898-1998)   \n",
       "4                 Indira Gandhi   (1917–1984)   \n",
       "5                 Morarji Desai   (1896–1995)   \n",
       "6                  Charan Singh   (1902–1987)   \n",
       "7                 Indira Gandhi   (1917–1984)   \n",
       "8                  Rajiv Gandhi   (1944–1991)   \n",
       "9                   V. P. Singh   (1931–2008)   \n",
       "10              Chandra Shekhar   (1927–2007)   \n",
       "11          P. V. Narasimha Rao   (1921–2004)   \n",
       "12         Atal Bihari Vajpayee  (1924- 2018)   \n",
       "13             H. D. Deve Gowda   (born 1933)   \n",
       "14           Inder Kumar Gujral   (1919–2012)   \n",
       "15         Atal Bihari Vajpayee   (1924-2018)   \n",
       "16               Manmohan Singh   (born 1932)   \n",
       "17                Narendra Modi   (born 1950)   \n",
       "\n",
       "                                       Term of office  \\\n",
       "0   15 August 1947 to 27 May 1964\\n16 years, 286 days   \n",
       "1                27 May 1964 to 9 June 1964,\\n13 days   \n",
       "2    9 June 1964 to 11 January 1966\\n1 year, 216 days   \n",
       "3         11 January 1966 to 24 January 1966\\n13 days   \n",
       "4   24 January 1966 to 24 March 1977\\n11 years, 59...   \n",
       "5   24 March 1977 to  28 July 1979 \\n2 year, 126 days   \n",
       "6           28 July 1979 to 14 January 1980\\n170 days   \n",
       "7   14 January 1980 to 31 October 1984\\n4 years, 2...   \n",
       "8   31 October 1984 to 2 December 1989\\n5 years, 3...   \n",
       "9       2 December 1989 to 10 November 1990\\n343 days   \n",
       "10         10 November 1990 to 21 June 1991\\n223 days   \n",
       "11     21 June 1991 to 16 May 1996\\n4 years, 330 days   \n",
       "12                16 May 1996 to 1 June 1996\\n16 days   \n",
       "13             1 June 1996 to 21 April 1997\\n324 days   \n",
       "14          21 April 1997 to 19 March 1998 \\n332 days   \n",
       "15    19 March 1998 to 22 May 2004 \\n6 years, 64 days   \n",
       "16    22 May 2004 to 26 May 2014   \\n10 years, 4 days   \n",
       "17                              26 May 2014 - Present   \n",
       "\n",
       "                                              Remarks  \n",
       "0   The first prime minister of India and the long...  \n",
       "1                            First acting PM of India  \n",
       "2   He has given the slogan of 'Jai Jawan Jai Kisa...  \n",
       "3                                                   -  \n",
       "4                First female Prime Minister of India  \n",
       "5   Oldest to become PM (81 years old) and first t...  \n",
       "6             Only PM who did not face the Parliament  \n",
       "7   The first lady who served as PM for the second...  \n",
       "8                Youngest to become PM (40 years old)  \n",
       "9   First PM to step down after a vote of no confi...  \n",
       "10              He belongs to  Samajwadi Janata Party  \n",
       "11                          First PM from south India  \n",
       "12                             PM for shortest tenure  \n",
       "13                          He belongs to  Janata Dal  \n",
       "14                                             ------  \n",
       "15  The first non-congress PM who completed a full...  \n",
       "16                                      First Sikh PM  \n",
       "17  4th Prime Minister of India who served two con...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead,\n",
    "# Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "# This task will be done in following steps:\n",
    "# 1. First get the webpage https://www.jagranjosh.com/\n",
    "# 2. Then You have to click on the GK option\n",
    "# 3. Then click on the List of all Prime Ministers of India\n",
    "# 4. Then scrap the mentioned data and make the DataFrame.\n",
    "import selenium\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "#from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "Webdriver_Path = Service(\"C:\\\\DataTrained\\\\FlipRobo\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=Webdriver_Path)\n",
    "#driver = webdriver.Chrome(r\"C:\\DataTrained\\FlipRobo\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "# opening the URL\n",
    "driver.get(\"https://www.jagranjosh.com/\")\n",
    "#maximize the window size  \n",
    "driver.maximize_window()  \n",
    "#delete the cookies  \n",
    "driver.delete_all_cookies()\n",
    "driver.implicitly_wait(2) # seconds\n",
    "#Click on Top Quotes\n",
    "driver.find_element(By.XPATH, \"//*[@id='1540978020504']/div[1]/header/div[3]/ul/li[9]/a\").click()\n",
    "time.sleep(2)\n",
    "#click on the List of all Prime Ministers of India\n",
    "driver.find_element(By.XPATH, \"//*[@id='popluarGK']/ul/li[2]/a\").click()\n",
    "\n",
    "Name=[]\n",
    "BornDead = []\n",
    "Termofoffice = []\n",
    "Remarks = []\n",
    "d =[]\n",
    "# to identify the table rows\n",
    "r = driver.find_elements(By.XPATH, \"//*[@id='itemdiv']/div[4]/span/div[2]/table/tbody/tr\")\n",
    "# to identify table columns\n",
    "c = driver.find_elements(By.XPATH, \"//*[@id='itemdiv']/div[4]/span/div[2]/table/tbody/tr/td\")\n",
    "#//*[@id=\"itemdiv\"]/div[4]/span/div[2]/table/tbody/tr[2]/td[1]\n",
    "# to get row count with len method\n",
    "rc = len (r)\n",
    "\n",
    "# to get column count with len method\n",
    "cc = len (c)\n",
    "\n",
    "for i in range (2, rc + 1) :\n",
    "# to traverse through the table column\n",
    "        cell = \"tr[\"+str(i)+\"]/td[2]\"\n",
    "        pm_name = driver.find_element(By.XPATH, \"//*[@id='itemdiv']/div[4]/span/div[2]/table/tbody/\"+cell+\"\")\n",
    "        Name.append(pm_name.text.strip())\n",
    "\n",
    "for i in range (2, rc + 1) :\n",
    "# to traverse through the table column\n",
    "        cell = \"tr[\"+str(i)+\"]/td[3]\"\n",
    "        Born_dead = driver.find_element(By.XPATH, \"//*[@id='itemdiv']/div[4]/span/div[2]/table/tbody/\"+cell+\"\")\n",
    "        BornDead.append(Born_dead.text.strip())\n",
    "\n",
    "for i in range (2, rc + 1) :\n",
    "# to traverse through the table column\n",
    "        cell = \"tr[\"+str(i)+\"]/td[4]\"\n",
    "        Term_office = driver.find_element(By.XPATH, \"//*[@id='itemdiv']/div[4]/span/div[2]/table/tbody/\"+cell+\"\")\n",
    "        Termofoffice.append(Term_office.text.strip())\n",
    "\n",
    "for i in range (2, rc + 1) :\n",
    "# to traverse through the table column\n",
    "        cell = \"tr[\"+str(i)+\"]/td[5]\"\n",
    "        Remark = driver.find_element(By.XPATH, \"//*[@id='itemdiv']/div[4]/span/div[2]/table/tbody/\"+cell+\"\")\n",
    "        Remarks.append(Remark.text.strip())\n",
    "#close the browser  \n",
    "driver.close()\n",
    "PMName_list = {'PMName':Name,'Born-Dead':BornDead,'Term of office':Termofoffice,'Remarks':Remarks}\n",
    "df = pd.DataFrame(PMName_list,columns =['PMName','Born-Dead','Term of office','Remarks'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f492540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CarName</th>\n",
       "      <th>Description</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drako GTE</td>\n",
       "      <td>The Drako GTE is a super sedan in every sense ...</td>\n",
       "      <td>Price: $1.2 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>De Tomaso P72</td>\n",
       "      <td>The De Tomaso P72 is basically the definition ...</td>\n",
       "      <td>Price: $1.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ferrari LaFerrari</td>\n",
       "      <td>At $1.4 million new, the Ferrari LaFerrari is ...</td>\n",
       "      <td>Price: $1.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pagani Huayra</td>\n",
       "      <td>Inarguably one of the prettiest cars on this l...</td>\n",
       "      <td>Price: $1.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>McLaren Elva</td>\n",
       "      <td>The McLaren Elva is one of the latest addition...</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Czinger 21C</td>\n",
       "      <td>You might not know the name Czinger yet, but t...</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ferrari Monza</td>\n",
       "      <td>Much like the roof-less McLaren Elva, the Ferr...</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gordon Murray T.33</td>\n",
       "      <td>The second and slightly more affordable superc...</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Koenigsegg Gemera</td>\n",
       "      <td>One of two Koenigsegg models on this list, the...</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Zenvo TSR-S</td>\n",
       "      <td>Hailing from Denmark, the Zenvo TSR-S debuted ...</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hennessey Venom F5</td>\n",
       "      <td>The Hennessey Venom GT was a record-breaker, t...</td>\n",
       "      <td>Price: $1.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bentley Bacalar</td>\n",
       "      <td>With just 12 total units produced, the Bentley...</td>\n",
       "      <td>Price: $1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hispano Suiza Carmen Boulogne</td>\n",
       "      <td>To call the Hispano Suiza Carmen Boulogne beau...</td>\n",
       "      <td>Price: $1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bentley Mulliner Batur</td>\n",
       "      <td>The electric onslaught is coming. Bentley says...</td>\n",
       "      <td>Price: $2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Deus Vayanne</td>\n",
       "      <td>The Deus Vayanne may not be a household name (...</td>\n",
       "      <td>Price: $2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SSC Tuatara</td>\n",
       "      <td>Although initially cloaked in controversy, SSC...</td>\n",
       "      <td>Price: $2.0 Million*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Lotus Evija</td>\n",
       "      <td>With a new Emira sports car and an Eletre elec...</td>\n",
       "      <td>Price: $2.1 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Aston Martin Vulcan</td>\n",
       "      <td>As with a few other cars on this list, the Ast...</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Delage D12</td>\n",
       "      <td>You may have heard of Delage before. In the ea...</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>McLaren Speedtail</td>\n",
       "      <td>What would you pay for the fastest production ...</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Rimac Nevera</td>\n",
       "      <td>The Rimac Nevera takes the title of most expen...</td>\n",
       "      <td>Price: $2.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pagani Utopia</td>\n",
       "      <td>First came the Zonda, then the Huayra, and now...</td>\n",
       "      <td>Price: $2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Pininfarina Battista</td>\n",
       "      <td>Aptly named after the company’s founder, Batti...</td>\n",
       "      <td>Price: $2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ferrari FXX K Evo</td>\n",
       "      <td>Sure, you could buy a normal LaFerrari (which ...</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Gordon Murray T.50</td>\n",
       "      <td>If the name Gordon Murray sounds familiar, it’...</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Lamborghini Countach</td>\n",
       "      <td>The name Countach may be iconic, but is it wor...</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Mercedes-AMG Project One</td>\n",
       "      <td>Mercedes has promised a production version of ...</td>\n",
       "      <td>Price: $2.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Aston Martin Victor</td>\n",
       "      <td>The folks at Aston Martin know a thing or two ...</td>\n",
       "      <td>Price: $3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Hennessey Venom F5 Roadster</td>\n",
       "      <td>The same Hennessey Venom F5 hypercar we all kn...</td>\n",
       "      <td>$3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Koenigsegg Jesko</td>\n",
       "      <td>The Koenigsegg Jesko, apart from being the fas...</td>\n",
       "      <td>Price: $3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Aston Martin Valkyrie</td>\n",
       "      <td>The upcoming Aston Martin hybrid hypercar hasn...</td>\n",
       "      <td>Price: $3.2 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>W Motors Lykan Hypersport</td>\n",
       "      <td>Dubai-based W Motors shocked the world with it...</td>\n",
       "      <td>Price: $3.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>McLaren Solus</td>\n",
       "      <td>One seat, 829 horsepower, and a top speed of o...</td>\n",
       "      <td>$3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Pagani Huayra Roadster BC</td>\n",
       "      <td>Following Pagani’s past playbook, a roadster v...</td>\n",
       "      <td>Price: $3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Bugatti Chiron Pur Sport</td>\n",
       "      <td>Another showstopper from the Geneva Motor Show...</td>\n",
       "      <td>Price: $3.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Lamborghini Sian</td>\n",
       "      <td>In several ways, the Sian represents a bridge ...</td>\n",
       "      <td>Price: $3.6 million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Koenigsegg CC850</td>\n",
       "      <td>The Koenigsegg CC850 was a surprise to be sure...</td>\n",
       "      <td>Price: $3.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Bugatti Chiron Super Sport 300+</td>\n",
       "      <td>Earlier this year, Bugatti captured the collec...</td>\n",
       "      <td>Price: $3.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Lamborghini Veneno</td>\n",
       "      <td>Lamborghini built just 14 examples of the Aven...</td>\n",
       "      <td>Price: $4.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Bugatti Bolide</td>\n",
       "      <td>Produced in extremely limited numbers atop the...</td>\n",
       "      <td>Price: $4.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Bugatti Mistral</td>\n",
       "      <td>The Bugatti Mistral sends the iconic W16 engin...</td>\n",
       "      <td>Price: $5.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Pagani Huayra Imola</td>\n",
       "      <td>Even though the new Utopia marks the next big ...</td>\n",
       "      <td>Price: $5.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Bugatti Divo</td>\n",
       "      <td>Among Bugatti’s recently debuted vehicles, the...</td>\n",
       "      <td>Price: $5.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>SP Automotive Chaos</td>\n",
       "      <td>SP Automotive (short for Spyros Panopoulos) is...</td>\n",
       "      <td>Price: $6.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Pagani Codalunga</td>\n",
       "      <td>The long list of pricey (new) Paganis ends wit...</td>\n",
       "      <td>Price: $7.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Mercedes-Maybach Exelero</td>\n",
       "      <td>Like many others before it, the Mercedes-Benz ...</td>\n",
       "      <td>Price: $8.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Bugatti Centodieci</td>\n",
       "      <td>Bugatti debuted the Centodieci at last year’s ...</td>\n",
       "      <td>Price: $9.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Rolls-Royce Sweptail</td>\n",
       "      <td>Rolls-Royce, expectedly, takes two of the top ...</td>\n",
       "      <td>Price: $12.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Bugatti La Voiture Noire</td>\n",
       "      <td>With a price tag of $13.4 million, the one-off...</td>\n",
       "      <td>Price: $13.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Rolls-Royce Boat Tail*</td>\n",
       "      <td>Rolls-Royce is back in the business of coachbu...</td>\n",
       "      <td>Price: $28.0 Million (est.)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            CarName  \\\n",
       "0                         Drako GTE   \n",
       "1                     De Tomaso P72   \n",
       "2                 Ferrari LaFerrari   \n",
       "3                     Pagani Huayra   \n",
       "4                      McLaren Elva   \n",
       "5                       Czinger 21C   \n",
       "6                     Ferrari Monza   \n",
       "7                Gordon Murray T.33   \n",
       "8                 Koenigsegg Gemera   \n",
       "9                       Zenvo TSR-S   \n",
       "10               Hennessey Venom F5   \n",
       "11                  Bentley Bacalar   \n",
       "12    Hispano Suiza Carmen Boulogne   \n",
       "13           Bentley Mulliner Batur   \n",
       "14                     Deus Vayanne   \n",
       "15                      SSC Tuatara   \n",
       "16                      Lotus Evija   \n",
       "17              Aston Martin Vulcan   \n",
       "18                       Delage D12   \n",
       "19                McLaren Speedtail   \n",
       "20                     Rimac Nevera   \n",
       "21                    Pagani Utopia   \n",
       "22             Pininfarina Battista   \n",
       "23                Ferrari FXX K Evo   \n",
       "24               Gordon Murray T.50   \n",
       "25             Lamborghini Countach   \n",
       "26         Mercedes-AMG Project One   \n",
       "27              Aston Martin Victor   \n",
       "28      Hennessey Venom F5 Roadster   \n",
       "29                 Koenigsegg Jesko   \n",
       "30            Aston Martin Valkyrie   \n",
       "31        W Motors Lykan Hypersport   \n",
       "32                    McLaren Solus   \n",
       "33        Pagani Huayra Roadster BC   \n",
       "34         Bugatti Chiron Pur Sport   \n",
       "35                 Lamborghini Sian   \n",
       "36                 Koenigsegg CC850   \n",
       "37  Bugatti Chiron Super Sport 300+   \n",
       "38               Lamborghini Veneno   \n",
       "39                   Bugatti Bolide   \n",
       "40                  Bugatti Mistral   \n",
       "41              Pagani Huayra Imola   \n",
       "42                     Bugatti Divo   \n",
       "43              SP Automotive Chaos   \n",
       "44                 Pagani Codalunga   \n",
       "45         Mercedes-Maybach Exelero   \n",
       "46               Bugatti Centodieci   \n",
       "47             Rolls-Royce Sweptail   \n",
       "48         Bugatti La Voiture Noire   \n",
       "49           Rolls-Royce Boat Tail*   \n",
       "\n",
       "                                          Description  \\\n",
       "0   The Drako GTE is a super sedan in every sense ...   \n",
       "1   The De Tomaso P72 is basically the definition ...   \n",
       "2   At $1.4 million new, the Ferrari LaFerrari is ...   \n",
       "3   Inarguably one of the prettiest cars on this l...   \n",
       "4   The McLaren Elva is one of the latest addition...   \n",
       "5   You might not know the name Czinger yet, but t...   \n",
       "6   Much like the roof-less McLaren Elva, the Ferr...   \n",
       "7   The second and slightly more affordable superc...   \n",
       "8   One of two Koenigsegg models on this list, the...   \n",
       "9   Hailing from Denmark, the Zenvo TSR-S debuted ...   \n",
       "10  The Hennessey Venom GT was a record-breaker, t...   \n",
       "11  With just 12 total units produced, the Bentley...   \n",
       "12  To call the Hispano Suiza Carmen Boulogne beau...   \n",
       "13  The electric onslaught is coming. Bentley says...   \n",
       "14  The Deus Vayanne may not be a household name (...   \n",
       "15  Although initially cloaked in controversy, SSC...   \n",
       "16  With a new Emira sports car and an Eletre elec...   \n",
       "17  As with a few other cars on this list, the Ast...   \n",
       "18  You may have heard of Delage before. In the ea...   \n",
       "19  What would you pay for the fastest production ...   \n",
       "20  The Rimac Nevera takes the title of most expen...   \n",
       "21  First came the Zonda, then the Huayra, and now...   \n",
       "22  Aptly named after the company’s founder, Batti...   \n",
       "23  Sure, you could buy a normal LaFerrari (which ...   \n",
       "24  If the name Gordon Murray sounds familiar, it’...   \n",
       "25  The name Countach may be iconic, but is it wor...   \n",
       "26  Mercedes has promised a production version of ...   \n",
       "27  The folks at Aston Martin know a thing or two ...   \n",
       "28  The same Hennessey Venom F5 hypercar we all kn...   \n",
       "29  The Koenigsegg Jesko, apart from being the fas...   \n",
       "30  The upcoming Aston Martin hybrid hypercar hasn...   \n",
       "31  Dubai-based W Motors shocked the world with it...   \n",
       "32  One seat, 829 horsepower, and a top speed of o...   \n",
       "33  Following Pagani’s past playbook, a roadster v...   \n",
       "34  Another showstopper from the Geneva Motor Show...   \n",
       "35  In several ways, the Sian represents a bridge ...   \n",
       "36  The Koenigsegg CC850 was a surprise to be sure...   \n",
       "37  Earlier this year, Bugatti captured the collec...   \n",
       "38  Lamborghini built just 14 examples of the Aven...   \n",
       "39  Produced in extremely limited numbers atop the...   \n",
       "40  The Bugatti Mistral sends the iconic W16 engin...   \n",
       "41  Even though the new Utopia marks the next big ...   \n",
       "42  Among Bugatti’s recently debuted vehicles, the...   \n",
       "43  SP Automotive (short for Spyros Panopoulos) is...   \n",
       "44  The long list of pricey (new) Paganis ends wit...   \n",
       "45  Like many others before it, the Mercedes-Benz ...   \n",
       "46  Bugatti debuted the Centodieci at last year’s ...   \n",
       "47  Rolls-Royce, expectedly, takes two of the top ...   \n",
       "48  With a price tag of $13.4 million, the one-off...   \n",
       "49  Rolls-Royce is back in the business of coachbu...   \n",
       "\n",
       "                          price  \n",
       "0           Price: $1.2 Million  \n",
       "1           Price: $1.3 Million  \n",
       "2           Price: $1.4 Million  \n",
       "3           Price: $1.4 Million  \n",
       "4           Price: $1.7 Million  \n",
       "5           Price: $1.7 Million  \n",
       "6           Price: $1.7 Million  \n",
       "7           Price: $1.7 Million  \n",
       "8           Price: $1.7 Million  \n",
       "9           Price: $1.7 Million  \n",
       "10          Price: $1.8 Million  \n",
       "11          Price: $1.9 Million  \n",
       "12          Price: $1.9 Million  \n",
       "13          Price: $2.0 Million  \n",
       "14          Price: $2.0 Million  \n",
       "15         Price: $2.0 Million*  \n",
       "16          Price: $2.1 Million  \n",
       "17          Price: $2.3 Million  \n",
       "18          Price: $2.3 Million  \n",
       "19          Price: $2.3 Million  \n",
       "20          Price: $2.4 Million  \n",
       "21          Price: $2.5 Million  \n",
       "22          Price: $2.5 Million  \n",
       "23          Price: $2.6 Million  \n",
       "24          Price: $2.6 Million  \n",
       "25          Price: $2.6 Million  \n",
       "26          Price: $2.7 Million  \n",
       "27          Price: $3.0 Million  \n",
       "28                 $3.0 Million  \n",
       "29          Price: $3.0 Million  \n",
       "30          Price: $3.2 Million  \n",
       "31          Price: $3.4 Million  \n",
       "32                 $3.5 Million  \n",
       "33          Price: $3.5 Million  \n",
       "34          Price: $3.6 Million  \n",
       "35          Price: $3.6 million  \n",
       "36          Price: $3.7 Million  \n",
       "37          Price: $3.9 Million  \n",
       "38          Price: $4.5 Million  \n",
       "39          Price: $4.7 Million  \n",
       "40          Price: $5.0 Million  \n",
       "41          Price: $5.4 Million  \n",
       "42          Price: $5.8 Million  \n",
       "43          Price: $6.4 Million  \n",
       "44          Price: $7.4 Million  \n",
       "45          Price: $8.0 Million  \n",
       "46          Price: $9.0 Million  \n",
       "47         Price: $12.8 Million  \n",
       "48         Price: $13.4 Million  \n",
       "49  Price: $28.0 Million (est.)  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10: Write a python program to display list of 50 Most expensive cars in the world (i.e.\n",
    "# Car name ,Description and Price) from https://www.motor1.com/\n",
    "# This task will be done in following steps:\n",
    "# 1. First get the webpage https://www.motor1.com/\n",
    "# 2. Then You have to click on the List option from Dropdown menu on leftside.\n",
    "# 3. Then click on 50 most expensive carsin the world..\n",
    "# 4. Then scrap the mentioned data and make the df\n",
    "\n",
    "import selenium\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "#from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "Webdriver_Path = Service(\"C:\\\\DataTrained\\\\FlipRobo\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=Webdriver_Path)\n",
    "#driver = webdriver.Chrome(r\"C:\\DataTrained\\FlipRobo\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "# opening the URL\n",
    "driver.get(\"https://www.motor1.com/\")\n",
    "#maximize the window size  \n",
    "driver.maximize_window()  \n",
    "#delete the cookies  \n",
    "driver.delete_all_cookies()\n",
    "time.sleep(3)\n",
    "#driver.implicitly_wait(2) # seconds\n",
    "#Click on features\n",
    "driver.find_element(By.XPATH, \"/html/body/div[3]/div[2]/div/div/div[3]/ul/li[5]/a\").click()\n",
    "time.sleep(2)\n",
    "#click on click on 50 most expensive cars in the world\n",
    "driver.find_element(By.XPATH, \"//div[@class='text-box']//h3//a[contains(@href, '/features/308149/most-expensive-new-cars-ever/')]\").click()\n",
    "time.sleep(5)\n",
    "CarName=[]\n",
    "Description = []\n",
    "price = []\n",
    "\n",
    "CarName_tags = driver.find_elements(By.XPATH, \"//h3[@class='subheader']\")\n",
    "for i in CarName_tags[0:50]:\n",
    "    CarName.append(i.text.strip())\n",
    "    time.sleep(1)\n",
    "\n",
    "for i in range (5, 104, 2) :\n",
    "        cell = \"p[\"+str(i)+\"]\"\n",
    "        Description_tags = driver.find_element(By.XPATH, \"//*[@id='article_box']/div[1]/div[2]/div[1]/\"+cell+\"\")\n",
    "        Description.append(Description_tags.text.strip())\n",
    "        time.sleep(1)\n",
    "        \n",
    "for i in range (4, 103, 2) :\n",
    "        cell = \"p[\"+str(i)+\"]/strong\"\n",
    "        price_tags = driver.find_element(By.XPATH, \"//*[@id='article_box']/div[1]/div[2]/div[1]/\"+cell+\"\")\n",
    "        price.append(price_tags.text.strip())\n",
    "        time.sleep(1)\n",
    "\n",
    "#close the browser  \n",
    "driver.close()  \n",
    "\n",
    "motor_list = {'CarName':CarName,'Description':Description,'price':price}\n",
    "df = pd.DataFrame(motor_list,columns =['CarName','Description','price'])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
